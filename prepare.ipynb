{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69db0e32-260b-4141-addd-c9f8eb475d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from acquire import get_codeup_blog, get_inshorts_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07452e0-4a4d-4b7c-8fd9-ee80a6ac8ece",
   "metadata": {},
   "source": [
    "# Data Preparation Exercises\n",
    "\n",
    "## 1\n",
    "\n",
    "Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "- Lowercase everything\n",
    "- Normalize unicode characters\n",
    "- Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2883bbc-7bf7-4fc0-baba-eb7881b9d2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A string to work with\n",
    "text = \"HERE is some text: α alpha  β beta | something * else. Someone's pencil.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9456e318-aeeb-4bfd-bf47-64a79bc6fc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here is some text: α alpha  β beta | something * else. someone's pencil.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase everything\n",
    "cleaned = text.lower()\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8546c2-6599-417c-ad36-0c551a124bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here is some text:  alpha   beta | something * else. someone's pencil.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize unicode characters\n",
    "cleaned = unicodedata.normalize('NFKD', cleaned).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9d792b-2656-42ef-82a8-787cfa32f1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here is some text  alpha   beta  something  else someone's pencil\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace special characters\n",
    "regexp = r\"[^a-z0-9'\\s]\"\n",
    "cleaned = re.sub(regexp, '', cleaned)\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021d812d-c72f-4eef-8a7b-8b60b6fca05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's put it in a function\n",
    "\n",
    "def basic_clean(text):\n",
    "    text = text.lower()\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    regexp = r\"[^a-z0-9'\\s]\"\n",
    "    text = re.sub(regexp, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc4624a-9783-428d-b110-de0666f5d984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here is some text  alpha   beta  something  else someone's pencil\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test it\n",
    "basic_clean(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c294ae-16c3-4d76-b118-91e776280dd2",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c7df5a-8ab8-4200-b9d0-328b00a2f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function that will create a tokenizer object and tokenize the input\n",
    "\n",
    "def tokenize(text):\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    return tokenizer.tokenize(text, return_str = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c492b4f-e696-460f-865f-e04d2f5d86fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here is some text alpha beta something else someone ' s pencil\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test it\n",
    "tokenize(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366a4be-8a86-44d7-abd4-7d961aed6e4e",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90c6fae-f55e-4031-aa20-a38fb620cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function that apply stemming to the input text\n",
    "\n",
    "def stem(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in text.split()]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "645c98be-6fb1-4238-a571-6295fb008d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here is some text alpha beta someth els someone' pencil\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test it\n",
    "stem(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be28bbc-c511-4e8e-ab4c-7e79d9f56158",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6699f1b-c867-4188-a73c-962c8eda0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a function that will apply lemmatization to the input text\n",
    "\n",
    "def lemmatize(text):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66b5048e-8d6f-4881-bcaa-778b2c74ca0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here is some text alpha beta something else someone's pencil\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test it\n",
    "lemmatize(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1305ec4-a2c8-4e86-830f-caa5990e6f3c",
   "metadata": {},
   "source": [
    "That didn't really change anything. Let's try a different string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc24ee76-ece4-4c6c-a427-ac62c49d50a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He study the principle of mathematical mumbo jumbo'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(\"He studies the principles of mathematical mumbo jumbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200449da-7fb5-4b52-b0b3-a343fae4d3a9",
   "metadata": {},
   "source": [
    "## 5\n",
    "\n",
    "Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845460fe-e8b9-4c1d-af2c-eb9d0f857d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try to add and remove words from the stopwords list\n",
    "\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list[ : 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34150d3a-97ae-4116-96e3-8c523de9f7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'hubba',\n",
       " 'bubba']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's try adding some words\n",
    "\n",
    "extra_words = [\n",
    "    'hubba',\n",
    "    'bubba'\n",
    "]\n",
    "\n",
    "stopword_list += extra_words\n",
    "stopword_list[-10 : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "307e9bcc-9ca1-4537-ae52-e1fb41ceee01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " 'wouldn',\n",
       " 'hubba',\n",
       " 'bubba']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's try removing some words\n",
    "\n",
    "exclude_words = [\n",
    "    \"wouldn't\",\n",
    "    \"won't\"\n",
    "]\n",
    "\n",
    "[stopword_list.remove(word) for word in exclude_words]\n",
    "\n",
    "stopword_list[-10 : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76b25a82-4303-4c7f-9541-3064f610d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create the function to remove all stopwords from the input text\n",
    "\n",
    "def remove_stopwords(text, extra_words = None, exclude_words = None):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    \n",
    "    # We need to add in the extra checks if the parameters are None in order to make the \n",
    "    # parameters optional.\n",
    "    stopword_list = set(stopword_list) | set(extra_words) if extra_words is not None else set(stopword_list)\n",
    "    stopword_list = stopword_list - set(exclude_words) if exclude_words is not None else stopword_list\n",
    "    \n",
    "    text = [word for word in text.split() if word not in stopword_list]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e74d2a2e-59a1-4f28-8814-5f8408ef4502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"text alpha beta something else someone's pencil\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test it\n",
    "remove_stopwords(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92dbe220-3858-4997-aaae-37e69eebff1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"here text something else someone's pencil\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(cleaned, extra_words = ['alpha', 'beta'], exclude_words = ['here'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39005956-7ee7-498b-bba4-81a97d4d1a13",
   "metadata": {},
   "source": [
    "## 6\n",
    "\n",
    "Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4af6b034-0806-4ad1-956c-f5e2243d7bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   title     99 non-null     object\n",
      " 1   content   99 non-null     object\n",
      " 2   category  99 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.4+ KB\n"
     ]
    }
   ],
   "source": [
    "news_df = get_inshorts_articles()\n",
    "news_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b4576-883f-43fa-9bcc-0313a37c7e17",
   "metadata": {},
   "source": [
    "## 7\n",
    "\n",
    "Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3aaee85d-54e5-4cc6-8a3f-70a7d4322fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220 entries, 0 to 219\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    220 non-null    object\n",
      " 1   date     220 non-null    object\n",
      " 2   content  218 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "codeup_df = get_codeup_blog()\n",
    "codeup_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "662b6ed3-e342-4039-a1a4-b5ca58bb4888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 218 entries, 0 to 219\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    218 non-null    object\n",
      " 1   date     218 non-null    object\n",
      " 2   content  218 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Not sure what those 2 nulls are, but let's just drop them.\n",
    "codeup_df = codeup_df.dropna()\n",
    "codeup_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93135aa3-39ef-493c-9407-0f047d638df8",
   "metadata": {},
   "source": [
    "## 8\n",
    "\n",
    "For each dataframe, produce the following columns:\n",
    "\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20f6a4b3-3208-4d76-9e19-56773fc82173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the news_df dataframe to produce a new dataframe with the contents we need.\n",
    "\n",
    "news_df = pd.DataFrame({\n",
    "    'title' : news_df.title,\n",
    "    'original' : news_df.content,\n",
    "    'clean' : news_df.content.apply(basic_clean).apply(tokenize).apply(remove_stopwords)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81feff20-4799-4474-9f98-f650e88940a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is Jared Birchall, who manages the world's...</td>\n",
       "      <td>Jared Birchall is the Managing Director of Exc...</td>\n",
       "      <td>jared birchall managing director excession fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Work ethic expectations from Twitter employees...</td>\n",
       "      <td>The world's richest man Elon Musk tweeted \"wor...</td>\n",
       "      <td>world ' richest man elon musk tweeted work eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best investment you'll make: Poonawalla sugges...</td>\n",
       "      <td>The Serum Institute of India's Adar Poonawalla...</td>\n",
       "      <td>serum institute india ' adar poonawalla sunday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon driver leaves 'kind' message for girl f...</td>\n",
       "      <td>Amazon Founder Jeff Bezos took to Instagram St...</td>\n",
       "      <td>amazon founder jeff bezos took instagram stori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseless and untrue: ED as Xiaomi alleges it t...</td>\n",
       "      <td>After Xiaomi alleged in a court filing that it...</td>\n",
       "      <td>xiaomi alleged court filing top executives fac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Who is Jared Birchall, who manages the world's...   \n",
       "1  Work ethic expectations from Twitter employees...   \n",
       "2  Best investment you'll make: Poonawalla sugges...   \n",
       "3  Amazon driver leaves 'kind' message for girl f...   \n",
       "4  Baseless and untrue: ED as Xiaomi alleges it t...   \n",
       "\n",
       "                                            original  \\\n",
       "0  Jared Birchall is the Managing Director of Exc...   \n",
       "1  The world's richest man Elon Musk tweeted \"wor...   \n",
       "2  The Serum Institute of India's Adar Poonawalla...   \n",
       "3  Amazon Founder Jeff Bezos took to Instagram St...   \n",
       "4  After Xiaomi alleged in a court filing that it...   \n",
       "\n",
       "                                               clean  \n",
       "0  jared birchall managing director excession fam...  \n",
       "1  world ' richest man elon musk tweeted work eth...  \n",
       "2  serum institute india ' adar poonawalla sunday...  \n",
       "3  amazon founder jeff bezos took instagram stori...  \n",
       "4  xiaomi alleged court filing top executives fac...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b28eb7f-45e7-450d-aadc-57ac3ea9c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create the stemmed and lemmatized columns\n",
    "news_df['stemmed'] = news_df.clean.apply(stem)\n",
    "news_df['lemmatized'] = news_df.clean.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5787f7d5-6833-44af-8542-bb862bab9485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who is Jared Birchall, who manages the world's...</td>\n",
       "      <td>Jared Birchall is the Managing Director of Exc...</td>\n",
       "      <td>jared birchall managing director excession fam...</td>\n",
       "      <td>jare birchal manag director excess famili offi...</td>\n",
       "      <td>jared birchall managing director excession fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Work ethic expectations from Twitter employees...</td>\n",
       "      <td>The world's richest man Elon Musk tweeted \"wor...</td>\n",
       "      <td>world ' richest man elon musk tweeted work eth...</td>\n",
       "      <td>world ' richest man elon musk tweet work ethic...</td>\n",
       "      <td>world ' richest man elon musk tweeted work eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best investment you'll make: Poonawalla sugges...</td>\n",
       "      <td>The Serum Institute of India's Adar Poonawalla...</td>\n",
       "      <td>serum institute india ' adar poonawalla sunday...</td>\n",
       "      <td>serum institut india ' adar poonawalla sunday ...</td>\n",
       "      <td>serum institute india ' adar poonawalla sunday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon driver leaves 'kind' message for girl f...</td>\n",
       "      <td>Amazon Founder Jeff Bezos took to Instagram St...</td>\n",
       "      <td>amazon founder jeff bezos took instagram stori...</td>\n",
       "      <td>amazon founder jeff bezo took instagram stori ...</td>\n",
       "      <td>amazon founder jeff bezos took instagram story...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseless and untrue: ED as Xiaomi alleges it t...</td>\n",
       "      <td>After Xiaomi alleged in a court filing that it...</td>\n",
       "      <td>xiaomi alleged court filing top executives fac...</td>\n",
       "      <td>xiaomi alleg court file top execut face threat...</td>\n",
       "      <td>xiaomi alleged court filing top executive face...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Who is Jared Birchall, who manages the world's...   \n",
       "1  Work ethic expectations from Twitter employees...   \n",
       "2  Best investment you'll make: Poonawalla sugges...   \n",
       "3  Amazon driver leaves 'kind' message for girl f...   \n",
       "4  Baseless and untrue: ED as Xiaomi alleges it t...   \n",
       "\n",
       "                                            original  \\\n",
       "0  Jared Birchall is the Managing Director of Exc...   \n",
       "1  The world's richest man Elon Musk tweeted \"wor...   \n",
       "2  The Serum Institute of India's Adar Poonawalla...   \n",
       "3  Amazon Founder Jeff Bezos took to Instagram St...   \n",
       "4  After Xiaomi alleged in a court filing that it...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  jared birchall managing director excession fam...   \n",
       "1  world ' richest man elon musk tweeted work eth...   \n",
       "2  serum institute india ' adar poonawalla sunday...   \n",
       "3  amazon founder jeff bezos took instagram stori...   \n",
       "4  xiaomi alleged court filing top executives fac...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  jare birchal manag director excess famili offi...   \n",
       "1  world ' richest man elon musk tweet work ethic...   \n",
       "2  serum institut india ' adar poonawalla sunday ...   \n",
       "3  amazon founder jeff bezo took instagram stori ...   \n",
       "4  xiaomi alleg court file top execut face threat...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  jared birchall managing director excession fam...  \n",
       "1  world ' richest man elon musk tweeted work eth...  \n",
       "2  serum institute india ' adar poonawalla sunday...  \n",
       "3  amazon founder jeff bezos took instagram story...  \n",
       "4  xiaomi alleged court filing top executive face...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the results\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3d664b1-15a4-45f2-a9dc-ac1cf2b9ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the same thing with the codeup_df dataframe\n",
    "\n",
    "codeup_df = pd.DataFrame({\n",
    "    'title' : codeup_df.title,\n",
    "    'original' : codeup_df.content,\n",
    "    'clean' : codeup_df.content.apply(basic_clean).apply(tokenize).apply(remove_stopwords)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b70c36c-da6c-42e1-8eb8-dcdc457fd7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df['stemmed'] = codeup_df.clean.apply(stem)\n",
    "codeup_df['lemmatized'] = codeup_df.clean.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09f2bea9-123b-4a46-93fa-225bfefad481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meet the new Codeup COO, Stephen Noteboom!</td>\n",
       "      <td>A big welcome to Stephen Noteboom, who will be...</td>\n",
       "      <td>big welcome stephen noteboom joining codeup ch...</td>\n",
       "      <td>big welcom stephen noteboom join codeup chief ...</td>\n",
       "      <td>big welcome stephen noteboom joining codeup ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Codeup Launches a Houston Bootcamp!</td>\n",
       "      <td>Houston, we have a problem: there aren’t enoug...</td>\n",
       "      <td>houston problem arent enough software develope...</td>\n",
       "      <td>houston problem arent enough softwar develop 6...</td>\n",
       "      <td>houston problem arent enough software develope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Codeup Named a Top 30 Coding School</td>\n",
       "      <td>Codeup Named a Top 30 Coding School\\n \\nWhile ...</td>\n",
       "      <td>codeup named top 30 coding school awards arent...</td>\n",
       "      <td>codeup name top 30 code school award arent nic...</td>\n",
       "      <td>codeup named top 30 coding school award arent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Codeup Success Story: Ryan Orsinger</td>\n",
       "      <td>Codeup Success Story: Ryan Orsinger\\n \\nWatch ...</td>\n",
       "      <td>codeup success story ryan orsinger watch video...</td>\n",
       "      <td>codeup success stori ryan orsing watch video i...</td>\n",
       "      <td>codeup success story ryan orsinger watch video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Codeup Success Story: Cole Reveal</td>\n",
       "      <td>Codeup Success Story: Cole Reveal\\nWatch the v...</td>\n",
       "      <td>codeup success story cole reveal watch video p...</td>\n",
       "      <td>codeup success stori cole reveal watch video p...</td>\n",
       "      <td>codeup success story cole reveal watch video p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0  Meet the new Codeup COO, Stephen Noteboom!   \n",
       "1         Codeup Launches a Houston Bootcamp!   \n",
       "2         Codeup Named a Top 30 Coding School   \n",
       "3         Codeup Success Story: Ryan Orsinger   \n",
       "4           Codeup Success Story: Cole Reveal   \n",
       "\n",
       "                                            original  \\\n",
       "0  A big welcome to Stephen Noteboom, who will be...   \n",
       "1  Houston, we have a problem: there aren’t enoug...   \n",
       "2  Codeup Named a Top 30 Coding School\\n \\nWhile ...   \n",
       "3  Codeup Success Story: Ryan Orsinger\\n \\nWatch ...   \n",
       "4  Codeup Success Story: Cole Reveal\\nWatch the v...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  big welcome stephen noteboom joining codeup ch...   \n",
       "1  houston problem arent enough software develope...   \n",
       "2  codeup named top 30 coding school awards arent...   \n",
       "3  codeup success story ryan orsinger watch video...   \n",
       "4  codeup success story cole reveal watch video p...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  big welcom stephen noteboom join codeup chief ...   \n",
       "1  houston problem arent enough softwar develop 6...   \n",
       "2  codeup name top 30 code school award arent nic...   \n",
       "3  codeup success stori ryan orsing watch video i...   \n",
       "4  codeup success stori cole reveal watch video p...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  big welcome stephen noteboom joining codeup ch...  \n",
       "1  houston problem arent enough software develope...  \n",
       "2  codeup named top 30 coding school award arent ...  \n",
       "3  codeup success story ryan orsinger watch video...  \n",
       "4  codeup success story cole reveal watch video p...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the results\n",
    "codeup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5b50f-0241-4204-93b3-033875433306",
   "metadata": {},
   "source": [
    "## 9\n",
    "\n",
    "Ask yourself:\n",
    "\n",
    "- If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "\n",
    "For this size of corpus I would prefer to use lemmatized text since this will not take too long to lemmatize.\n",
    "\n",
    "- If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "\n",
    "For this size of corpus I would still prefer lemmatizing. It will take some time to lemmatize, but I suspect not so long that it would be unreasonable.\n",
    "\n",
    "- If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?\n",
    "\n",
    "For this size of corpus I would prefer stemming. That much data would not only take a very long time to lemmatize, but would also be heavily charged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
