{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9a6e06-7dc3-4030-9f70-b957b29211f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "from prepare import prepare_messages\n",
    "from get_db_url import get_db_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00909fae-1d05-433e-856b-d1f53f1e571f",
   "metadata": {},
   "source": [
    "# Model Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8738754-491a-4c23-80b4-eb4d695bb152",
   "metadata": {},
   "source": [
    "## Acquire and Prepare Spam Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf4e270-ad57-4dbe-90e1-efaac44d2d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   object\n",
      " 1   text    5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 130.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# We'll use the spam data since it is labeled.\n",
    "df = pd.read_sql('SELECT * FROM spam;', get_db_url('spam_db'), index_col = 'id')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e479b5f-674f-46c8-8ec8-bce8e2f73731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "id                                                         \n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "935d8582-894a-4a6f-b4ee-917b1ea680a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   label       5572 non-null   object\n",
      " 1   original    5572 non-null   object\n",
      " 2   clean       5572 non-null   object\n",
      " 3   stemmed     5572 non-null   object\n",
      " 4   lemmatized  5572 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 261.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = prepare_messages(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ccd07e-4d6f-47d0-96ce-5c287aaa3f11",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf87a9c-5751-4f3d-b940-3b788642e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split the data into two sets: train and test\n",
    "train, test = train_test_split(df, train_size = 0.8, test_size = 0.2, random_state = 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ce591-5443-4362-94b8-b8791a3781b3",
   "metadata": {},
   "source": [
    "## Establish a Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa7b1195-b9c1-4487-87af-303fa00103c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     3854\n",
       "spam     603\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's establish a baseline model.\n",
    "# First let's see the value counts of ham and spam in the label feature.\n",
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ed9a738-c239-4025-839b-7ea349c3a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most messages are ham so predicting ham will be the baseline.\n",
    "baseline = pd.DataFrame({'label' : 'ham'}, index = train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7fee4e-b9d7-489a-ac24-9a619e417153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8647072021539152"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train.label, baseline.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d59f88-7220-40ae-9a92-31a502c7ce77",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08205a52-0d85-452c-b30f-0c5848be8ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll use a CountVectorizer first\n",
    "cv = CountVectorizer()\n",
    "X_bow = cv.fit_transform(train.clean)\n",
    "\n",
    "# Let's create and fit a decision tree using the cleaned version of the messages\n",
    "model = DecisionTreeClassifier(max_depth = 5, random_state = 24)\n",
    "model.fit(X_bow, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "265093ff-5ad2-46f3-b16e-8b13c6093f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9288759255104331"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_bow, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25799476-e89d-40ff-87e2-d8b36dbd65c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6965174129353234"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(train.label, model.predict(X_bow), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57751012-8c99-48a8-957b-5395b12e211b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9264573991031391"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(cv.transform(test.clean), test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe2a9bf-8b29-4373-82e5-ad81a7618ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6527777777777778"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test.label, model.predict(cv.transform(test.clean)), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e5a74-76b1-4a20-a3a9-122e870ea646",
   "metadata": {},
   "source": [
    "This model has good performance. Let's try using the tfidf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94286810-b050-448a-ba3f-0b4a67500555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a TfidfVectorizer now\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(train.clean)\n",
    "\n",
    "# Let's create the same model by this time using the tfidf vectorizer we just created.\n",
    "model = DecisionTreeClassifier(max_depth = 5, random_state = 24)\n",
    "model.fit(X_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5cb08d-3304-4d94-a89a-3d739fe52e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9544536683868072"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3e34cc-41ea-4626-8c97-55b4f208eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06633499170812604"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(train.label, model.predict(X_bow), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bf434a1-e71f-4510-8eee-9a5c3497e7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354260089686098"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(tfidf.transform(test.clean), test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fc90fc5-4855-40fe-8890-98718d8334a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06944444444444445"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test.label, model.predict(cv.transform(test.clean)), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4ba2d-e20a-4d15-a5ef-85c811ee6318",
   "metadata": {},
   "source": [
    "We got slightly better performance with the tfidf vectorizer. Now let's try using the stemmed version of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "922182e9-fe48-4d92-a7c5-6179f1d27698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=24)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can re-use the cv vectorizer\n",
    "X_bow = cv.fit_transform(train.stemmed)\n",
    "\n",
    "# Again we'll use the same model but with the new X_bow.\n",
    "model = DecisionTreeClassifier(max_depth = 5, random_state = 24)\n",
    "model.fit(X_bow, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90ece2b5-2ff0-4e22-b160-e40beda8d137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306708548350908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_bow, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81d692e2-c0f0-4793-b1ba-e000e934c239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.494195688225539"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(train.label, model.predict(X_bow), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04da3199-ed7c-4aac-85ec-fb0f07613c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9273542600896861"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(cv.transform(test.stemmed), test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f94f4269-60ff-40f4-bf8c-1a328bf7784a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2777777777777778"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test.label, model.predict(cv.transform(test.clean)), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed80436c-926a-45de-9928-db73da235ea7",
   "metadata": {},
   "source": [
    "The performance is slightly better than the count vectorizer model using the simple cleaned version of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecf77d00-5861-4af3-a295-1b795a0f6df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=24)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the tfidf vectorizer\n",
    "X_tfidf = tfidf.fit_transform(train.stemmed)\n",
    "\n",
    "# And now the model with the new X_tfidf.\n",
    "model = DecisionTreeClassifier(max_depth = 5, random_state = 24)\n",
    "model.fit(X_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad70b73f-59bc-4b42-b659-35335b568608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9551267668835539"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bf2348b-5748-4baa-a8eb-95514ac50907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14427860696517414"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(train.label, model.predict(X_bow), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a5f605c-f21e-4eee-a946-cb9a4511fdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9282511210762332"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(tfidf.transform(test.stemmed), test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cde36d8-8c12-4661-8ba2-3e4a2a7a7914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04861111111111111"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test.label, model.predict(cv.transform(test.clean)), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fefd136-b75c-4067-9448-88323e6df399",
   "metadata": {},
   "source": [
    "There is a larger drop off in performance compared to the model that used the simple cleaned version of the messages. Next we'll use the lemmatized version of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80f4b9ce-1b49-48df-b276-fddcf564eee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=24)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The cv vectorizer again\n",
    "X_bow = cv.fit_transform(train.lemmatized)\n",
    "\n",
    "# Now the same model again with the new X_bow\n",
    "model = DecisionTreeClassifier(max_depth = 5, random_state = 24)\n",
    "model.fit(X_bow, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cef557d9-3caf-4e1c-b397-72f21c0095ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9299977563383441"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_bow, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68339e13-560f-4ae6-99b3-0adc2843a9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4892205638474295"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(train.label, model.predict(X_bow), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3c7424a-dc10-4907-ab8a-7d36eaedf0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9264573991031391"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(cv.transform(test.lemmatized), test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43b6cb14-6e0f-423a-be2f-92167674c929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4166666666666667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test.label, model.predict(cv.transform(test.clean)), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a3d7e-317c-420c-b682-5a6b92e85ad0",
   "metadata": {},
   "source": [
    "Similar performance to the model with the cleaned version of the messages. Now the tfidf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "648f3e3d-b1c6-4842-b026-7c085b314f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, random_state=24)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the tfidf vectorizer again\n",
    "X_tfidf = tfidf.fit_transform(train.lemmatized)\n",
    "\n",
    "# Now the model, again\n",
    "model = DecisionTreeClassifier(max_depth = 5, random_state = 24)\n",
    "model.fit(X_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cda33424-f7b3-472f-b8ae-891d31fe6118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9540049360556428"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_tfidf, train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70dff2ea-a648-439b-9581-e1c3a9aaf175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1691542288557214"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(train.label, model.predict(X_bow), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "496baed6-56a7-42e6-a672-cab38793929a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318385650224216"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(tfidf.transform(test.lemmatized), test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0791a7e6-5e2c-4a4c-bf40-83b8913de06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1527777777777778"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test.label, model.predict(cv.transform(test.clean)), pos_label = 'spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7620ee-70f4-49d5-8bba-98468ff875ae",
   "metadata": {},
   "source": [
    "This is similar performance to the same model with the cleaned version of the messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bdc504-4ee4-46f5-b2c1-58a063fde2a9",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "This time let's focus on the recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c187c2ca-c823-43f6-9cce-67432f8855a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean train recall: 0.8905472636815921\n",
      "clean test recall: 0.7708333333333334\n",
      "\n",
      "stemmed train recall: 0.8922056384742952\n",
      "stemmed test recall: 0.7847222222222222\n",
      "\n",
      "lemmatized train recall: 0.8905472636815921\n",
      "lemmatized test recall: 0.7638888888888888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This time we'll try putting the code in a loop.\n",
    "# We'll use the BernoulliNB model from SK learn.\n",
    "# We'll use the count vectorizer.\n",
    "\n",
    "columns = [\n",
    "    'clean',\n",
    "    'stemmed',\n",
    "    'lemmatized'\n",
    "]\n",
    "\n",
    "for column in columns:\n",
    "    cv = CountVectorizer()\n",
    "    X_bow = cv.fit_transform(train[column])\n",
    "    \n",
    "    model = BernoulliNB()\n",
    "    model.fit(X_bow, train.label)\n",
    "    \n",
    "    print(f'{column} train recall: {recall_score(train.label, model.predict(X_bow), pos_label = \"spam\")}')\n",
    "    print(f'{column} test recall: {recall_score(test.label, model.predict(cv.transform(test[column])), pos_label = \"spam\")}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247c0f19-d1e3-4414-ba5e-63d972de8fbd",
   "metadata": {},
   "source": [
    "For all three we have similar recall scores. Let's try building models with n-grams this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17c60d45-c47e-4632-8a3a-98096dc84220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean train recall: 0.48258706467661694\n",
      "clean test recall: 0.20833333333333334\n",
      "\n",
      "stemmed train recall: 0.4975124378109453\n",
      "stemmed test recall: 0.2013888888888889\n",
      "\n",
      "lemmatized train recall: 0.4892205638474295\n",
      "lemmatized test recall: 0.20833333333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in columns:\n",
    "    # We'll use bi-grams and tri-grams\n",
    "    cv = CountVectorizer(ngram_range = (2, 3))\n",
    "    X_bow = cv.fit_transform(train[column])\n",
    "    \n",
    "    model = BernoulliNB()\n",
    "    model.fit(X_bow, train.label)\n",
    "    \n",
    "    print(f'{column} train recall: {recall_score(train.label, model.predict(X_bow), pos_label = \"spam\")}')\n",
    "    print(f'{column} test recall: {recall_score(test.label, model.predict(cv.transform(test[column])), pos_label = \"spam\")}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce6282-1b0a-4a24-acf0-9cc8e16e35da",
   "metadata": {},
   "source": [
    "Wow, that's significantly worse. Let's try only bi-grams with the tfidf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2573eac4-b054-49fb-bdb4-e696d0a9c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean train recall: 0.4975124378109453\n",
      "clean test recall: 0.2361111111111111\n",
      "\n",
      "stemmed train recall: 0.5290215588723052\n",
      "stemmed test recall: 0.2638888888888889\n",
      "\n",
      "lemmatized train recall: 0.5058043117744611\n",
      "lemmatized test recall: 0.24305555555555555\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in columns:\n",
    "    tfidf = TfidfVectorizer(ngram_range = (2, 2))\n",
    "    X_bow = tfidf.fit_transform(train[column])\n",
    "    \n",
    "    model = BernoulliNB()\n",
    "    model.fit(X_bow, train.label)\n",
    "    \n",
    "    print(f'{column} train recall: {recall_score(train.label, model.predict(X_bow), pos_label = \"spam\")}')\n",
    "    print(f'{column} test recall: {recall_score(test.label, model.predict(tfidf.transform(test[column])), pos_label = \"spam\")}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe790a-21f2-4b69-9984-7b8fd7c9a605",
   "metadata": {},
   "source": [
    "That's still really bad.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "Now let's try a random forest model with the count vectorizer and only single words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4171bcde-3c14-4d75-9f67-d7567c8cb9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean, depth = 3, train recall: 0.0\n",
      "clean, depth = 3, test recall: 0.0\n",
      "\n",
      "clean, depth = 4, train recall: 0.009950248756218905\n",
      "clean, depth = 4, test recall: 0.013888888888888888\n",
      "\n",
      "clean, depth = 5, train recall: 0.008291873963515755\n",
      "clean, depth = 5, test recall: 0.006944444444444444\n",
      "\n",
      "clean, depth = 6, train recall: 0.03150912106135987\n",
      "clean, depth = 6, test recall: 0.013888888888888888\n",
      "\n",
      "clean, depth = 7, train recall: 0.06799336650082918\n",
      "clean, depth = 7, test recall: 0.041666666666666664\n",
      "\n",
      "clean, depth = 8, train recall: 0.0945273631840796\n",
      "clean, depth = 8, test recall: 0.06944444444444445\n",
      "\n",
      "stemmed, depth = 3, train recall: 0.0\n",
      "stemmed, depth = 3, test recall: 0.0\n",
      "\n",
      "stemmed, depth = 4, train recall: 0.0\n",
      "stemmed, depth = 4, test recall: 0.0\n",
      "\n",
      "stemmed, depth = 5, train recall: 0.008291873963515755\n",
      "stemmed, depth = 5, test recall: 0.006944444444444444\n",
      "\n",
      "stemmed, depth = 6, train recall: 0.04643449419568822\n",
      "stemmed, depth = 6, test recall: 0.020833333333333332\n",
      "\n",
      "stemmed, depth = 7, train recall: 0.06965174129353234\n",
      "stemmed, depth = 7, test recall: 0.0763888888888889\n",
      "\n",
      "stemmed, depth = 8, train recall: 0.14925373134328357\n",
      "stemmed, depth = 8, test recall: 0.11805555555555555\n",
      "\n",
      "lemmatized, depth = 3, train recall: 0.0\n",
      "lemmatized, depth = 3, test recall: 0.0\n",
      "\n",
      "lemmatized, depth = 4, train recall: 0.0\n",
      "lemmatized, depth = 4, test recall: 0.0\n",
      "\n",
      "lemmatized, depth = 5, train recall: 0.003316749585406302\n",
      "lemmatized, depth = 5, test recall: 0.006944444444444444\n",
      "\n",
      "lemmatized, depth = 6, train recall: 0.02155887230514096\n",
      "lemmatized, depth = 6, test recall: 0.006944444444444444\n",
      "\n",
      "lemmatized, depth = 7, train recall: 0.06135986733001658\n",
      "lemmatized, depth = 7, test recall: 0.0763888888888889\n",
      "\n",
      "lemmatized, depth = 8, train recall: 0.0912106135986733\n",
      "lemmatized, depth = 8, test recall: 0.06944444444444445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We'll try various values of max_depth\n",
    "\n",
    "for column in columns:\n",
    "    for depth in range(3, 9):\n",
    "        cv = CountVectorizer()\n",
    "        X_bow = cv.fit_transform(train[column])\n",
    "\n",
    "        model = RandomForestClassifier(max_depth = depth)\n",
    "        model.fit(X_bow, train.label)\n",
    "\n",
    "        print(f'{column}, depth = {depth}, train recall: {recall_score(train.label, model.predict(X_bow), pos_label = \"spam\")}')\n",
    "        print(f'{column}, depth = {depth}, test recall: {recall_score(test.label, model.predict(cv.transform(test[column])), pos_label = \"spam\")}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab9ad0a4-56e9-4b23-8e53-ef633fa73793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean, depth = 3, train recall: 0.0\n",
      "clean, depth = 3, test recall: 0.0\n",
      "\n",
      "clean, depth = 4, train recall: 0.0\n",
      "clean, depth = 4, test recall: 0.0\n",
      "\n",
      "clean, depth = 5, train recall: 0.004975124378109453\n",
      "clean, depth = 5, test recall: 0.006944444444444444\n",
      "\n",
      "clean, depth = 6, train recall: 0.014925373134328358\n",
      "clean, depth = 6, test recall: 0.006944444444444444\n",
      "\n",
      "clean, depth = 7, train recall: 0.01990049751243781\n",
      "clean, depth = 7, test recall: 0.006944444444444444\n",
      "\n",
      "clean, depth = 8, train recall: 0.04477611940298507\n",
      "clean, depth = 8, test recall: 0.020833333333333332\n",
      "\n",
      "stemmed, depth = 3, train recall: 0.0\n",
      "stemmed, depth = 3, test recall: 0.0\n",
      "\n",
      "stemmed, depth = 4, train recall: 0.0\n",
      "stemmed, depth = 4, test recall: 0.0\n",
      "\n",
      "stemmed, depth = 5, train recall: 0.0\n",
      "stemmed, depth = 5, test recall: 0.0\n",
      "\n",
      "stemmed, depth = 6, train recall: 0.009950248756218905\n",
      "stemmed, depth = 6, test recall: 0.0\n",
      "\n",
      "stemmed, depth = 7, train recall: 0.03316749585406302\n",
      "stemmed, depth = 7, test recall: 0.020833333333333332\n",
      "\n",
      "stemmed, depth = 8, train recall: 0.07131011608623548\n",
      "stemmed, depth = 8, test recall: 0.027777777777777776\n",
      "\n",
      "lemmatized, depth = 3, train recall: 0.0\n",
      "lemmatized, depth = 3, test recall: 0.0\n",
      "\n",
      "lemmatized, depth = 4, train recall: 0.0\n",
      "lemmatized, depth = 4, test recall: 0.0\n",
      "\n",
      "lemmatized, depth = 5, train recall: 0.0\n",
      "lemmatized, depth = 5, test recall: 0.0\n",
      "\n",
      "lemmatized, depth = 6, train recall: 0.0\n",
      "lemmatized, depth = 6, test recall: 0.0\n",
      "\n",
      "lemmatized, depth = 7, train recall: 0.009950248756218905\n",
      "lemmatized, depth = 7, test recall: 0.0\n",
      "\n",
      "lemmatized, depth = 8, train recall: 0.06135986733001658\n",
      "lemmatized, depth = 8, test recall: 0.034722222222222224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try that again with bi-grams\n",
    "\n",
    "for column in columns:\n",
    "    for depth in range(3, 9):\n",
    "        cv = CountVectorizer(ngram_range = (1, 2))\n",
    "        X_bow = cv.fit_transform(train[column])\n",
    "\n",
    "        model = RandomForestClassifier(max_depth = depth)\n",
    "        model.fit(X_bow, train.label)\n",
    "\n",
    "        print(f'{column}, depth = {depth}, train recall: {recall_score(train.label, model.predict(X_bow), pos_label = \"spam\")}')\n",
    "        print(f'{column}, depth = {depth}, test recall: {recall_score(test.label, model.predict(cv.transform(test[column])), pos_label = \"spam\")}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad0e9ee-ae17-4b36-9f41-bd48d28c6be1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Overall it looks like the BernoulliNB model with the CountVectorizer produces the best results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
